# Because we need the x and y axis to display every node,
# not just the nodes that have connections to each other,
# make sure that ggplot does not drop unused factor levels
scale_x_discrete(drop = FALSE) +
scale_y_discrete(drop = FALSE) +
xlab(NULL) + ylab(NULL) +
scale_fill_manual(values = colors[c(-5, -10, -12)],
labels = leagues[c(-5, -10, -12)],
name = "Leagues") +
theme(
# Rotate the x-axis lables so they are legible
axis.text.x = element_blank(),
axis.text.y = element_blank(),
# Force the plot into a square aspect ratio
aspect.ratio = 1
# Hide the legend (optional)
)
seriea.adjacency
# Betweenness Centrality of Whole network
whole.between <- betweenness(network, weights = E(network)$weight, normalized = T)
whole.between <- sort(whole.between, decreasing = TRUE)
head(round(whole.between, 3), 10)
index <- as.numeric(gsub(x = names(head(whole.between, 10)), pattern = "team", replacement = ""))
team_nodes[index, ]
whole.eigen <- eigen_centrality(network, directed = TRUE)
whole.eigen <- sort(whole.eigen$vector, decreasing = TRUE)
head(round(whole.eigen, 3), 10)
index <- as.numeric(gsub(x = names(head(whole.eigen, 10)), pattern = "team", replacement = ""))
team_nodes[index, ]
whole.degree <- degree(network, mode = "total", normalized = TRUE)
whole.degree <- sort(whole.degree, decreasing = TRUE)
head(round(whole.degree, 3), 10)
index <- as.numeric(gsub(x = names(head(whole.degree, 10)), pattern = "team", replacement = ""))
team_nodes[index, ]
whole.in <- degree_distribution(network, cumulative = FALSE, mode = 'in')
whole.in <- data.frame(Degree = 0:(length(whole.in) - 1),
Proportion = whole.in)
whole1 <- ggplot(whole.in[-1, ], aes(x = Degree, y = Proportion)) +
geom_line() +
geom_point() +
scale_x_log10(breaks = 1:31,
labels = c(1, rep("", 8), 10, rep("", 9), 20, rep("", 9), 30, "")) +
scale_y_log10() +
stat_function(fun = function(x){(log(x^(-.66))) - 0.42}, color = 'red', size = 1.2) +
xlab(expression(k[In])) + ylab(expression(P(k[In])))
whole1
temp <- ggplot_build(whole1)$data[[3]]
(temp[10, 2] - temp[2, 2])/(temp[10, 1] - temp[2, 1])
whole.out <- degree_distribution(network, cumulative = FALSE, mode = 'out')
whole.out <- data.frame(Degree = 0:(length(whole.out) - 1),
Proportion = whole.out)
whole2 <- ggplot(whole.out[-1, ], aes(x = Degree, y = Proportion)) +
geom_line() +
geom_point() +
scale_x_log10(breaks = 1:31,
labels = c(1, rep("", 8), 10, rep("", 9), 20, rep("", 9), 30, "")) +
scale_y_log10() +
stat_function(fun = function(x){(log(x^(-.8))) - 0.5}, color = 'red', size = 1.2) +
xlab(expression(k[Out])) + ylab(expression(P(k[Out])))
whole2
temp <- ggplot_build(whole2)$data[[3]]
(temp[10, 2] - temp[2, 2])/(temp[10, 1] - temp[2, 1])
library(gridExtra)
# Betweenness Centrality of Whole network
epl.between <- betweenness(epl.network, normalized = TRUE)
epl.between <- sort(epl.between, decreasing = TRUE)
head(round(epl.between, 3), 10)
index <- as.numeric(gsub(x = names(head(epl.between, 10)), pattern = "team", replacement = ""))
team_nodes[index, ]
epl.eigen <- eigen_centrality(epl.network, directed = TRUE)
epl.eigen <- sort(epl.eigen$vector, decreasing = TRUE)
head(round(epl.eigen, 3), 10)
index <- as.numeric(gsub(x = names(head(epl.eigen, 10)), pattern = "team", replacement = ""))
team_nodes[index, ]
epl.degree <- degree(epl.network, mode = "total", normalized = TRUE)
epl.degree <- sort(epl.degree, decreasing = TRUE)
head(round(epl.degree, 3), 10)
index <- as.numeric(gsub(x = names(head(epl.degree, 10)), pattern = "team", replacement = ""))
team_nodes[index, ]
epl.dd <- degree_distribution(epl.network, cumulative = FALSE)
epl.dd <- data.frame(Degree = 0:(length(epl.dd) - 1),
Proportion = epl.dd)
epl.dd
ggplot(epl.dd[-1, ], aes(x = Degree, y = Proportion)) +
geom_point() +
geom_line() +
scale_x_log10() + scale_y_log10() + geom_smooth(method = "lm")
# Betweenness Centrality of Whole network
laliga.between <- betweenness(laliga.network, normalized = TRUE)
laliga.between <- sort(laliga.between, decreasing = TRUE)
head(round(laliga.between, 3), 10)
index <- as.numeric(gsub(x = names(head(laliga.between, 10)), pattern = "team", replacement = ""))
team_nodes[index, ]
laliga.eigen <- eigen_centrality(laliga.network, directed = TRUE, scale = TRUE)
laliga.eigen <- sort(laliga.eigen$vector, decreasing = TRUE)
head(round(laliga.eigen, 3), 10)
index <- as.numeric(gsub(x = names(head(laliga.eigen, 10)), pattern = "team", replacement = ""))
team_nodes[index, ]
laliga.degree <- degree(laliga.network, mode = "total", normalized = TRUE)
laliga.degree <- sort(laliga.degree, decreasing = TRUE)
head(round(laliga.degree, 3), 10)
index <- as.numeric(gsub(x = names(head(laliga.degree, 10)), pattern = "team", replacement = ""))
team_nodes[index, ]
laliga.dd <- degree_distribution(laliga.network)
laliga.dd <- data.frame(Degree = 0:(length(laliga.dd) - 1),
Proportion = laliga.dd)
laliga.dd
ggplot(laliga.dd[-1, ], aes(x = Degree, y = Proportion)) +
geom_point() +
geom_line() +
scale_x_log10() + scale_y_log10() + geom_smooth(method = "lm")
# Betweenness Centrality of Whole network
bundes.between <- betweenness(bundes.network, normalized = TRUE)
bundes.between <- sort(bundes.between, decreasing = TRUE)
head(round(bundes.between, 3), 10)
index <- as.numeric(gsub(x = names(head(bundes.between, 10)), pattern = "team", replacement = ""))
team_nodes[index, ]
bundes.eigen <- eigen_centrality(bundes.network, directed = TRUE, scale = TRUE)
bundes.eigen <- sort(bundes.eigen$vector, decreasing = TRUE)
head(round(bundes.eigen, 3), 10)
index <- as.numeric(gsub(x = names(head(bundes.eigen, 10)), pattern = "team", replacement = ""))
team_nodes[index, ]
bundes.degree <- degree(bundes.network, mode = "total", normalized = TRUE)
bundes.degree <- sort(bundes.degree, decreasing = TRUE)
head(round(bundes.degree, 3), 10)
index <- as.numeric(gsub(x = names(head(bundes.degree, 10)), pattern = "team", replacement = ""))
team_nodes[index, ]
bundes.dd <- degree_distribution(bundes.network)
bundes.dd <- data.frame(Degree = 0:(length(bundes.dd) - 1),
Proportion = bundes.dd)
bundes.dd
ggplot(bundes.dd[-1, ], aes(x = Degree, y = Proportion)) +
geom_point() +
geom_line() +
scale_x_log10() + scale_y_log10() + geom_smooth(method = "lm")
# Betweenness Centrality of Whole network
seriea.between <- betweenness(seriea.network, normalized = TRUE)
seriea.between <- sort(seriea.between, decreasing = TRUE)
head(round(seriea.between, 3), 10)
index <- as.numeric(gsub(x = names(head(seriea.between, 10)), pattern = "team", replacement = ""))
team_nodes[index, ]
seriea.eigen <- eigen_centrality(seriea.network, directed = TRUE, scale = TRUE)
seriea.eigen <- sort(seriea.eigen$vector, decreasing = TRUE)
head(round(seriea.eigen, 3), 10)
index <- as.numeric(gsub(x = names(head(seriea.eigen, 10)), pattern = "team", replacement = ""))
team_nodes[index, ]
seriea.degree <- degree(seriea.network, mode = "total", normalized = TRUE)
seriea.degree <- sort(seriea.degree, decreasing = TRUE)
head(round(seriea.degree, 3), 10)
index <- as.numeric(gsub(x = names(head(seriea.degree, 10)), pattern = "team", replacement = ""))
team_nodes[index, ]
seriea.dd <- degree_distribution(seriea.network)
seriea.dd <- data.frame(Degree = 0:(length(seriea.dd) - 1),
Proportion = seriea.dd)
seriea.dd
insert_minor <- function(major_labs, n_minor) {labs <-
c( sapply( major_labs, function(x) c(x, rep("", 4) ) ) )
labs[1:(length(labs)-n_minor)]}
ggplot(seriea.dd[-1, ], aes(x = Degree, y = Proportion)) +
geom_point() +
geom_line() +
scale_x_log10() + scale_y_log10() + geom_smooth(method = "lm")
networkInfo <- function(network){
numEdge <- length(E(network))
numNode <- length(V(network))
sumWeight <- round(sum(E(network)$weight), 2)
averageWeight <- round(sumWeight/numNode, 2)
cat("#Edge:", numEdge, "\n#Node:", numNode, "\nTotal Transfer Fee:", paste0(sumWeight, "m\nAverage Transfer Fee per Event: ", paste0(averageWeight, "m\n")))
}
networkInfo(epl.network)
networkInfo(laliga.network)
networkInfo(bundes.network)
networkInfo(seriea.network)
write_csv(team_links, "~/Desktop/team_links.csv")
write_csv(team_nodes, "~/Desktop/team_nodes.csv")
library(RJSONIO)
library(dplyr)
library(stringr)
library(readr)
json <- read_lines("~/Google Drive/log.txt")
head(json, 40)
index <- !(1:length(json) %% 15 == 1 | 1:length(json) %% 15 == 4 |  1:length(json) %% 15 == 5 | 1:length(json) %% 15 == 6 | 1:length(json) %% 15 == 7 | 1:length(json) %% 15 == 8 | 1:length(json) %% 15 == 12)
json <- json[index]
head(json, 40)
clean_json <- json %>%
str_replace("ObjectId\\(", "") %>%
str_replace("ISODate\\(", "") %>%
str_replace("\\)", "") %>%
str_replace("    ", "") %>%
str_replace(" :", ":") %>%
str_replace("\\}", "\\}\n")
head(clean_json, 40)
write(clean_json, "~/Google Drive/clean_log.json")
test <- paste(clean_json, collapse = " ")
write(test, "~/Google Drive/test.txt")
going_data <- jsonlite::stream_in(file("~/Google Drive/test.txt"))
head(going_data)
library(readr)
write_csv(going_data, "~/Desktop/Baek.csv")
credit <- read.csv("~/Google Drive/ML Lecture/8 Tree Based/credit.csv")
summary(credit)
# install.packages(c("rpart", "rpart.plot"))
library(caret)
library(rpart)
library(rpart.plot)
# CART Algorithm
set.seed(123)
trainIdx <- sample(1:nrow(credit), size = nrow(credit) * 0.7)
trainCredit <- credit[trainIdx, ]
testCredit <- credit[-trainIdx, ]
creditTree <- rpart(default ~ ., data = trainCredit, method = "class")
creditTree
rpart.plot(creditTree)
rpart.plot(creditTree)
?rpart.plot
predictCredit <- predict(creditTree, testCredit, type = "class")
predictCredit <- predict(creditTree, testCredit, type = "class")
confusionMatrix(predictCredit, testCredit$default)
install.packages(c("randomForest", "ranger"))
library(randomForest)
set.seed(1234)
RF_Credit <- randomForest(default ~ ., data = trainCredit, importance = TRUE, replace = TRUE, proximity = TRUE, mtry = 4)
RF_Credit
varImpPlot(RF_Credit)
pred_RF_Credit <- predict(RF_Credit, testCredit)
pred_RF_Credit <- predict(RF_Credit, testCredit)
confusionMatrix(pred_RF_Credit, testCredit$default)
head(pred_RF_Credit)
confusionMatrix(pred_RF_Credit, testCredit$default)
library(ranger)
set.seed(1234)
RF_Credit2 <- ranger(default ~ ., data = trainCredit,
num.trees = 2000, importance = "impurity", replace = TRUE, write.forest = TRUE)
RF_Credit2
pred_RF_Credit <- predict(RF_Credit2, testCredit)
pred_RF_Credit
pred_RF_Credit$predictions
confusionMatrix(pred_RF_Credit$predictions, testCredit$default)
# install.packages("xgboost")
library(xgboost)
doMC::registerDoMC(4)
str(trainCredit)
trainLabel <- as.numeric(trainCredit$default) - 1
testLabel <- as.numeric(testCredit$default) - 1
trainMat <- model.matrix(default ~ ., data = trainCredit)[, -1]
testMat <- model.matrix(default ~ ., data = testCredit)[, -1]
View(trainMat)
trainMat <- model.matrix(default ~ ., data = trainCredit)[, -1]
testMat <- model.matrix(default ~ ., data = testCredit)[, -1]
credit_xgboost <- xgboost(data = trainMat,
label = trainLabel,
max.depth = 6,
eta = 0.3,
subsample = 1,
nrounds = 10,
objective = "binary:logistic",
eval_metric = "error"
)
xgb_pred <- predict(credit_xgboost, testMat)
head(xgb_pred)
xgb_pred <- ifelse(xgb_pred > 0.5, 1, 0)
confusionMatrix(xgb_pred, testCredit$default)
confusionMatrix(xgb_pred, testLabel)
set.seed(1234)
credit_xgboost <- xgboost(data = trainMat,
label = trainLabel,
max.depth = 6,
eta = 0.3,
subsample = 1,
nrounds = 10,
objective = "binary:logistic",
eval_metric = "error"
)
xgb_pred <- predict(credit_xgboost, testMat)
xgb_pred <- ifelse(xgb_pred > 0.5, 1, 0)
confusionMatrix(xgb_pred, testLabel)
library(caret)
cv.ctrl <- trainControl(method = "repeatedcv", number = 5, allowParallel = TRUE)
xgb.grid <- expand.grid(nrounds = seq(10, 30, by = 5),
eta = c(0.1, 0.3, 0.5),
max_depth = c(3, 5, 7),
gamma = 0,
colsample_bytree = c(0.8, 0.9, 1),
min_child_weight = c(0.8, 0.9, 1),
subsample = 1
)
head(xgb.grid)
set.seed(1234)
xgb_tune <- train(trainMat, factor(trainLabel),
method = "xgbTree", trControl = cv.ctrl,
tuneGrid = xgb.grid, verbose = TRUE,
metric = "error", nthread = 4)
xgb_tune$bestTune
xgb_tune$bestTune
credit_xgboost2 <- xgboost(data = trainMat,
label = trainLabel,
nrounds = 20,
max_depth = 3,
eta = 0.5,
gamma = 0,
colsample_bytree = 0.8,
min_child_weight = 0.8,
subsample = 1,
objective = "binary:logistic",
eval_metric = "error")
xgb_pred2 <- predict(credit_xgboost2, testMat)
xgb_pred2 <- ifelse(xgb_pred2 > 0.5, 1, 0)
confusionMatrix(xgb_pred2, testLabel)
confusionMatrix(xgb_pred, testLabel)
xgb_tune$bestTune
options(scipen=10)
library(data.table)
library(ggplot2)
library(mltools)  # For generating CV folds and one-hot-encoding
library(class)  # K-Nearest Neighbors model
library(LiblineaR)  # Support Vector Machine and Logistic Regression
setwd("Google Drive/ML Lecture/MLPB-master/Problems/Classify Dart Throwers/")
train <- fread("_Data/train.csv")
test <- fread("_Data/test.csv")
train[, Competitor := factor(Competitor)]
test[, Competitor := factor(Competitor)]
train[, DistFromCenter := sqrt(XCoord^2 + YCoord^2)]
test[, DistFromCenter := sqrt(XCoord^2 + YCoord^2)]
train[, FoldID := folds(Competitor, nfolds=5, stratified=TRUE, seed=2016)]  # mltools function
knnCV <- list()
knnCV[["Features"]] <- c("XCoord", "YCoord")
knnCV[["ParamGrid"]] <- CJ(k=seq(1, 30))
knnCV[["BestScore"]] <- 0
for(i in seq_len(nrow(knnCV[["ParamGrid"]]))){
# Get the ith set of parameters
params <- knnCV[["ParamGrid"]][i]
# Build an empty vector to store scores from each train/test fold
scores <- numeric()
# Build an empty list to store predictions from each train/test fold
predsList <- list()
# Loop through each test fold, fit model to training folds and make predictions on test fold
for(foldID in 1:5){
# Build the train/test folds
testFold <- train[J(FoldID=foldID), on="FoldID"]
trainFolds <- train[!J(FoldID=foldID), on="FoldID"]  # Exclude fold i from trainFolds
# Train the model & make predictions
testFold[, Pred := knn(train=trainFolds[, knnCV$Features, with=FALSE], test=testFold[, knnCV$Features, with=FALSE], cl=trainFolds$Competitor, k=params$k)]
predsList <- c(predsList, list(testFold[, list(ID, FoldID, Pred)]))
# Evaluate predictions (accuracy rate) and append score to scores vector
score <- mean(testFold$Pred == testFold$Competitor)
scores <- c(scores, score)
}
# Measure the overall score. If best, tell knnCV
score <- mean(scores)
# Insert the score into ParamGrid
knnCV[["ParamGrid"]][i, Score := score][]
print(paste("Params:", paste(colnames(knnCV[["ParamGrid"]][i]), knnCV[["ParamGrid"]][i], collapse = " | ")))
if(score > knnCV[["BestScore"]]){
knnCV[["BestScores"]] <- scores
knnCV[["BestScore"]] <- score
knnCV[["BestParams"]] <- knnCV[["ParamGrid"]][i]
knnCV[["BestPreds"]] <- rbindlist(predsList)
}
}
knnCV[["BestParams"]]
knnCV[["ParamGrid"]]
ggplot(knnCV[["ParamGrid"]], aes(x=k, y=Score))+geom_line()+geom_point()
svmCV <- list()
svmCV[["Features"]] <- c("XCoord", "YCoord", "DistFromCenter")
svmCV[["ParamGrid"]] <- CJ(type=1:5, cost=c(.01, .1, 1, 10, 100, 1000, 2000), Score=NA_real_)
svmCV[["BestScore"]] <- 0
for(i in seq_len(nrow(svmCV[["ParamGrid"]]))){
# Get the ith set of parameters
params <- svmCV[["ParamGrid"]][i]
# Build an empty vector to store scores from each train/test fold
scores <- numeric()
# Build an empty list to store predictions from each train/test fold
predsList <- list()
# Loop through each test fold, fit model to training folds and make predictions on test fold
for(foldID in 1:5){
# Build the train/test folds
testFold <- train[J(FoldID=foldID), on="FoldID"]
trainFolds <- train[!J(FoldID=foldID), on="FoldID"]  # Exclude fold i from trainFolds
# Train the model & make predictions
svm <- LiblineaR(data=trainFolds[, svmCV$Features, with=FALSE], target=trainFolds$Competitor, type=params$type, cost=params$cost)
testFold[, Pred := predict(svm, testFold[, svmCV$Features, with=FALSE])$predictions]
predsList <- c(predsList, list(testFold[, list(ID, FoldID, Pred)]))
# Evaluate predictions (accuracy rate) and append score to scores vector
score <- mean(testFold$Pred == testFold$Competitor)
scores <- c(scores, score)
}
# Measure the overall score. If best, tell svmCV
score <- mean(scores)
# Insert the score into ParamGrid
svmCV[["ParamGrid"]][i, Score := score][]
print(paste("Params:", paste(colnames(svmCV[["ParamGrid"]][i]), svmCV[["ParamGrid"]][i], collapse = " | ")))
if(score > svmCV[["BestScore"]]){
svmCV[["BestScores"]] <- scores
svmCV[["BestScore"]] <- score
svmCV[["BestParams"]] <- svmCV[["ParamGrid"]][i]
svmCV[["BestPreds"]] <- rbindlist(predsList)
}
}
doMC::registerDoMC(4)
for(foldID in 1:5){
# Build the train/test folds
testFold <- train[J(FoldID=foldID), on="FoldID"]
trainFolds <- train[!J(FoldID=foldID), on="FoldID"]  # Exclude fold i from trainFolds
# Train the model & make predictions
svm <- LiblineaR(data=trainFolds[, svmCV$Features, with=FALSE], target=trainFolds$Competitor, type=params$type, cost=params$cost)
testFold[, Pred := predict(svm, testFold[, svmCV$Features, with=FALSE])$predictions]
predsList <- c(predsList, list(testFold[, list(ID, FoldID, Pred)]))
# Evaluate predictions (accuracy rate) and append score to scores vector
score <- mean(testFold$Pred == testFold$Competitor)
scores <- c(scores, score)
}
score <- mean(scores)
svmCV[["ParamGrid"]][i, Score := score][]
print(paste("Params:", paste(colnames(svmCV[["ParamGrid"]][i]), svmCV[["ParamGrid"]][i], collapse = " | ")))
svmCV <- list()
svmCV[["Features"]] <- c("XCoord", "YCoord", "DistFromCenter")
svmCV[["ParamGrid"]] <- CJ(type=1:5, cost=c(.01, .1, 1, 10, 100, 1000, 2000), Score=NA_real_)
svmCV[["BestScore"]] <- 0
for(i in seq_len(nrow(svmCV[["ParamGrid"]]))){
# Get the ith set of parameters
params <- svmCV[["ParamGrid"]][i]
# Build an empty vector to store scores from each train/test fold
scores <- numeric()
# Build an empty list to store predictions from each train/test fold
predsList <- list()
# Loop through each test fold, fit model to training folds and make predictions on test fold
for(foldID in 1:5){
# Build the train/test folds
testFold <- train[J(FoldID=foldID), on="FoldID"]
trainFolds <- train[!J(FoldID=foldID), on="FoldID"]  # Exclude fold i from trainFolds
# Train the model & make predictions
svm <- LiblineaR(data=trainFolds[, svmCV$Features, with=FALSE], target=trainFolds$Competitor, type=params$type, cost=params$cost)
testFold[, Pred := predict(svm, testFold[, svmCV$Features, with=FALSE])$predictions]
predsList <- c(predsList, list(testFold[, list(ID, FoldID, Pred)]))
# Evaluate predictions (accuracy rate) and append score to scores vector
score <- mean(testFold$Pred == testFold$Competitor)
scores <- c(scores, score)
}
# Measure the overall score. If best, tell svmCV
score <- mean(scores)
# Insert the score into ParamGrid
svmCV[["ParamGrid"]][i, Score := score][]
print(paste("Params:", paste(colnames(svmCV[["ParamGrid"]][i]), svmCV[["ParamGrid"]][i], collapse = " | ")))
if(score > svmCV[["BestScore"]]){
svmCV[["BestScores"]] <- scores
svmCV[["BestScore"]] <- score
svmCV[["BestParams"]] <- svmCV[["ParamGrid"]][i]
svmCV[["BestPreds"]] <- rbindlist(predsList)
}
}
svmCV[["BestParams"]]
svmCV[["ParamGrid"]]
ggplot(svmCV[["ParamGrid"]], aes(x=cost, y=Score, color=factor(type)))+geom_line()+geom_point()
metas.knn <- knnCV[["BestPreds"]]
metas.svm <- svmCV[["BestPreds"]]
train[metas.knn, Meta.knn := Pred, on="ID"]
train[metas.svm, Meta.svm := Pred, on="ID"]
train <- one_hot(train, cols=c("Meta.knn", "Meta.svm"), dropCols=FALSE)
lrCV <- list()
lrCV[["Features"]] <- setdiff(colnames(train), c("ID", "FoldID", "Competitor", "Meta.knn", "Meta.svm"))
lrCV[["ParamGrid"]] <- CJ(type=c(0, 6, 7), cost=c(.001, .01, .1, 1, 10, 100))
lrCV[["BestScore"]] <- 0
for(i in seq_len(nrow(lrCV[["ParamGrid"]]))){
# Get the ith set of parameters
params <- lrCV[["ParamGrid"]][i]
# Build an empty vector to store scores from each train/test fold
scores <- numeric()
# Build an empty list to store predictions from each train/test fold
predsList <- list()
# Loop through each test fold, fit model to training folds and make predictions on test fold
for(foldID in 1:5){
# Build the train/test folds
testFold <- train[J(FoldID=foldID), on="FoldID"]
trainFolds <- train[!J(FoldID=foldID), on="FoldID"]  # Exclude fold i from trainFolds
# Train the model & make predictions
logreg <- LiblineaR(data=trainFolds[, lrCV$Features, with=FALSE], target=trainFolds$Competitor, type=params$type, cost=params$cost)
testFold[, Pred := predict(logreg, testFold[, lrCV$Features, with=FALSE])$predictions]
predsList <- c(predsList, list(testFold[, list(ID, FoldID, Pred)]))
# Evaluate predictions (accuracy rate) and append score to scores vector
score <- mean(testFold$Pred == testFold$Competitor)
scores <- c(scores, score)
}
# Measure the overall score. If best, tell lrCV
score <- mean(scores)
# Insert the score into ParamGrid
lrCV[["ParamGrid"]][i, Score := score][]
print(paste("Params:", paste(colnames(lrCV[["ParamGrid"]][i]), lrCV[["ParamGrid"]][i], collapse = " | ")))
if(score > lrCV[["BestScore"]]){
lrCV[["BestScores"]] <- scores
lrCV[["BestScore"]] <- score
lrCV[["BestParams"]] <- lrCV[["ParamGrid"]][i]
lrCV[["BestPreds"]] <- rbindlist(predsList)
}
}
knnCV[["BestParams"]]
svmCV[["BestParams"]]
lrCV[["BestParams"]]
test[, Meta.knn := knn(train=train[, knnCV$Features, with=FALSE], test=test[, knnCV$Features, with=FALSE], cl=train$Competitor, k=knnCV$BestParams$k)]
svm <- LiblineaR(data=train[, svmCV$Features, with=FALSE], target=train$Competitor, type=svmCV$BestParams$type, cost=svmCV$BestParams$cost)
test[, Meta.svm := predict(svm, test[, svmCV$Features, with=FALSE])$predictions]
test <- one_hot(test, cols=c("Meta.knn", "Meta.svm"), dropCols=FALSE)
logreg <- LiblineaR(data=trainFolds[, lrCV$Features, with=FALSE], target=trainFolds$Competitor, type=lrCV$BestParams$type, cost=lrCV$BestParams$cost)
test[, Pred.ensemble := predict(logreg, test[, lrCV$Features, with=FALSE])$predictions]
mean(test$Competitor == test$Meta.knn)
mean(test$Competitor == test$Meta.svm)
mean(test$Competitor == test$Pred.ensemble)
logreg
mean(test$Competitor == test$Meta.knn)
mean(test$Competitor == test$Pred.ensemble)
mean(test$Competitor == test$Meta.knn)
mean(test$Competitor == test$Meta.svm)
markdown("2016-12-28-model-stacking.Rmd", "machine_learning")
